\chapter{OpenMP Locks}
\label{ch:locks}
\index{locks}

This chapter studies another important synchronization mechanism in shared-memory parallel programming: \emph{locks}. Locks are used to ensure \textbf{orderly access} to a region of code that must not be executed concurrently by multiple threads. The fundamental property achieved using locks is \textbf{mutual exclusion}, as defined in Chapter~\ref{ch:mutual-exclusion}.

The discussion is motivated by the need to selectively \emph{sequentialize} parts of an otherwise parallel program. While threads are typically free to execute independently and concurrently, certain code regions---called \emph{critical regions}\index{critical region}---must be accessed in a controlled fashion to avoid incorrect behavior.

\begin{ppnote}
\textbf{Relationship to previous chapters:} This chapter provides the practical API for implementing the mutual exclusion concepts from Chapter~\ref{ch:mutual-exclusion}. The \texttt{single} directive from Chapter~\ref{ch:thread-control} executes code once; locks allow repeated, serialized execution by all threads.
\end{ppnote}

\section{What Is a Lock?}

\begin{ppdefn}
A \ppterm{lock} is an abstraction that protects a specific region of code. Conceptually:
\begin{itemize}
    \item Multiple threads may want to execute the same region of code $C$.
    \item At most one thread is allowed to execute $C$ at any given time.
    \item Other threads must wait until the currently executing thread exits $C$.
\end{itemize}
In simple terms, a lock \emph{locks} a region of code so that only one thread can be inside that region at a time.
\end{ppdefn}

\section{Locks vs \texttt{single}}
\label{sec:locks-vs-single}

At first glance, locks may appear similar to the OpenMP construct \texttt{\#pragma omp single} (see Section~\ref{sec:single-directive}). However, the semantics are fundamentally different:

\begin{figure}[h]
    \centering
    \fbox{\parbox{0.8\textwidth}{\centering
    \textbf{[Figure: Locks vs Single Comparison]}\\[0.5em]
    \textbf{Left:} \texttt{single} --- One thread executes block once; others wait at barrier.\\[0.3em]
    \textbf{Right:} Lock --- All threads eventually execute, but one at a time. No barrier; threads proceed independently after releasing.}}
    \caption{Semantic difference between \texttt{single} directive and lock-based synchronization.}
    \label{fig:locks-vs-single}
\end{figure}

\begin{ppkey}
\begin{itemize}
    \item \textbf{\texttt{single}:} The code region $C$ is executed by exactly one thread, and never by the others.
    \item \textbf{Lock:} Every thread \emph{may eventually execute} $C$, but execution is serialized---one thread at a time.
\end{itemize}
Thus, a lock enables \emph{multiple executions in an orderly fashion}, whereas \texttt{single} enforces a \emph{single execution}.
\end{ppkey}

\begin{ppnote}
Importantly, \texttt{single} introduces an implicit barrier at the end (unless \texttt{nowait} is specified), whereas \textbf{locks do not introduce any implicit barrier}. Threads proceed independently after unlocking.
\end{ppnote}

\section{Conceptual Model of Locking}

Consider a shared lock variable $V$:
\begin{itemize}
    \item $V$ resides in shared memory.
    \item Initially, $V = 0$ (unlocked).
    \item A thread that sets $V = 1$ acquires the lock.
    \item Releasing the lock resets $V$ to $0$.
\end{itemize}

All threads compete to acquire $V$. The first thread that succeeds enters the critical region $C$. Other threads wait.

\subsection{Spin Waiting}

\begin{ppdefn}
In a naive implementation, waiting threads repeatedly check the value of $V$ in a loop. This is called \ppterm{spin waiting} or \ppterm{busy waiting}.
\end{ppdefn}

\begin{ppprogram}{Naive spin lock implementation}{prog:spin-lock}
\begin{lstlisting}[language=C11]
while (V != 0) {
    // spin
}
V = 1;  // acquire lock
\end{lstlisting}
\end{ppprogram}

\begin{pppitfall}
The naive implementation in Program~\ref{prog:spin-lock} has a \emph{race condition}\index{race condition}: multiple threads may simultaneously observe \texttt{V == 0} and both proceed to set \texttt{V = 1}. Real lock implementations use atomic operations (such as compare-and-swap\index{compare-and-swap}, or CAS) to avoid this. This is why the \texttt{omp\_lock\_t} abstraction exists---it handles these low-level details correctly.
\end{pppitfall}

Modern processors and runtimes optimize spin waiting behavior, but the fundamental idea remains: waiting threads repeatedly check the lock state until it becomes available.

\section{Sequentialization in a Parallel Program}

A natural question arises:

\begin{quote}
\emph{If $n$ threads execute the same region $C$ sequentially using a lock, is this equivalent to executing $n$ copies of $C$ sequentially?}
\end{quote}

\begin{ppkey}
Yes---and that is the point. Locks provide a programming-language-level abstraction that allows the programmer to intentionally serialize execution of a critical region within a parallel program.

Without such an abstraction, threads would execute $C$ concurrently and cause incorrect behavior. Locks give the programmer explicit control over where and how sequentialization occurs.
\end{ppkey}

\section{Fairness, Starvation, and Scheduling}

\begin{pppitfall}
It is possible for a thread to:
\begin{itemize}
    \item Release a lock,
    \item Reach the next iteration,
    \item And re-acquire the lock again before other threads.
\end{itemize}
This can lead to \ppterm{starvation}, where some threads never get a chance to execute $C$.
\end{pppitfall}

Whether starvation happens depends on:
\begin{itemize}
    \item The lock implementation,
    \item Scheduling policies,
    \item Hardware and runtime behavior.
\end{itemize}

Designing \emph{fair} synchronization primitives is an active research topic spanning operating systems, architecture, and programming languages.

\section{Race Conditions vs Data Races}

The lecture emphasizes an important distinction:

\begin{ppdefn}
\begin{description}
    \item[\ppterm{Race condition}:] Multiple threads competing to acquire a resource. This is \emph{intentional} and necessary for locks.
    \item[\ppterm{Data race}:] Concurrent access to shared data where at least one access is a write and accesses are unordered. This is \emph{incorrect}.
\end{description}
\end{ppdefn}

\begin{ppkey}
Locks \textbf{allow race conditions} (competition to acquire the lock) but \textbf{prevent data races} inside the protected region.

Since only one thread executes $C$ at a time, shared variables inside $C$ cannot be concurrently modified.
\end{ppkey}

\section{How Do Threads Observe Unlocking?}

Threads waiting for a lock repeatedly read the shared lock variable from memory. Conceptually:
\begin{itemize}
    \item The lock variable $V$ is stored at a memory address.
    \item Waiting threads issue repeated read requests for $V$.
    \item When $V$ changes (unlock), threads observe the update and compete to acquire it.
\end{itemize}

The runtime system ensures that only one thread succeeds in acquiring the lock, even if multiple threads attempt simultaneously.

\section{OpenMP Lock Primitives}
\label{sec:lock-primitives}
\index{omp\_lock\_t}\index{omp\_nest\_lock\_t}

OpenMP exposes lock functionality explicitly through library calls~\cite{openmp-spec}. Unlike the directive-based constructs (\texttt{parallel}, \texttt{single}, \texttt{critical}), locks are managed via explicit function calls, giving the programmer fine-grained control.

\subsection{Lock Types}

\begin{ppnote}
OpenMP provides two lock types:
\begin{itemize}
    \item \texttt{omp\_lock\_t}: Normal (non-nestable) lock.
    \item \texttt{omp\_nest\_lock\_t}: Nestable lock that allows re-acquisition by the same thread.
\end{itemize}
\end{ppnote}

\subsection{Lock API}

\begin{ppprogram}{OpenMP lock API}{prog:lock-api}
\begin{lstlisting}[language=OpenMP]
void omp_init_lock(omp_lock_t *lock);
void omp_set_lock(omp_lock_t *lock);    // acquire
void omp_unset_lock(omp_lock_t *lock);  // release
void omp_destroy_lock(omp_lock_t *lock);

int omp_test_lock(omp_lock_t *lock);    // try-acquire
\end{lstlisting}
\end{ppprogram}

\begin{ppkey}
\texttt{omp\_test\_lock} returns immediately:
\begin{itemize}
    \item Non-zero if the lock was acquired,
    \item Zero otherwise (no blocking).
\end{itemize}
\end{ppkey}

\subsection{Using \texttt{omp\_test\_lock}}

\begin{ppprogram}{Using test lock for non-blocking acquisition}{prog:test-lock-usage}
\begin{lstlisting}[language=OpenMP]
int flag = 0;
while (!flag) {
    flag = omp_test_lock(&lock);
    // Optionally do other work while waiting
}
// Lock acquired, proceed with critical section
\end{lstlisting}
\end{ppprogram}

\section{Complete Lock Example}

\begin{ppexample}
Here is a complete example demonstrating proper lock usage to protect a shared counter:
\end{ppexample}

\begin{ppprogram}{Protecting a shared counter with locks}{prog:lock-counter}
\begin{lstlisting}[language=OpenMP]
#include <omp.h>
#include <stdio.h>

int main() {
    int counter = 0;
    omp_lock_t lock;
    
    omp_init_lock(&lock);
    
    #pragma omp parallel
    {
        for (int i = 0; i < 1000; i++) {
            omp_set_lock(&lock);
            counter++;  // Critical section
            omp_unset_lock(&lock);
        }
    }
    
    omp_destroy_lock(&lock);
    
    printf("Counter = %d\n", counter);
    return 0;
}
\end{lstlisting}
\end{ppprogram}

\begin{ppnote}
Without the lock in Program~\ref{prog:lock-counter}, the increment operation would suffer from lost updates---the final counter value would be unpredictable and less than expected.
\end{ppnote}

\section{Key Takeaway}

\begin{ppkey}
Locks help achieve \textbf{race-freedom} (specifically, freedom from data races) when accessing a critical region. They enforce \textbf{mutual exclusion} among competing threads without introducing implicit synchronization barriers.
\end{ppkey}

\section{Summary}

This chapter covered the OpenMP lock API for implementing mutual exclusion:
\begin{itemize}
    \item Locks enable serialized access to critical regions, unlike \texttt{single} which executes code only once.
    \item The \texttt{omp\_lock\_t} type and associated functions (\texttt{init}, \texttt{set}, \texttt{unset}, \texttt{destroy}, \texttt{test}) provide explicit lock management.
    \item Locks introduce race conditions (threads competing for the lock) but prevent data races inside the protected region.
    \item Fairness and starvation are implementation-dependent concerns.
\end{itemize}

\section{Exercises}

\begin{ppexercises}
  \ppexercise{Explain why \texttt{omp\_single} cannot replace locks when all threads must eventually execute a critical region.}
  
  \ppexercise{Write a small OpenMP program where threads increment a shared counter:
  \begin{itemize}
      \item First without locks (observe incorrect result),
      \item Then using \texttt{omp\_lock\_t}.
  \end{itemize}
  Compile with \texttt{gcc -fopenmp} and run multiple times. Explain the difference in results.}
  
  \ppexercise{Consider a lock that is unfair. Explain how starvation may arise with a looped critical region. Draw a timeline showing a possible execution where thread~0 acquires the lock 10 times before thread~1 acquires it once.}
  
  \ppexercise{Classify the following as race condition, data race, both, or neither, and justify your answer:
  \begin{itemize}
      \item Two threads calling \texttt{omp\_set\_lock} on the same lock
      \item Two threads incrementing the same variable without synchronization
      \item Two threads reading the same constant
      \item One thread writing while another reads without synchronization
  \end{itemize}}
  
  \ppexercise{Compare and contrast using \texttt{\#pragma omp critical} with explicit locks via \texttt{omp\_lock\_t}. When would you prefer one over the other? Consider both correctness and performance.}
  
  \ppexercise{Modify Program~\ref{prog:lock-counter} to use \texttt{omp\_test\_lock} with a fallback to doing other work when the lock is not available. Measure whether this improves performance compared to blocking on \texttt{omp\_set\_lock}.}
\end{ppexercises}

\section*{References}
\addcontentsline{toc}{section}{References}
See the OpenMP Specification~\cite{openmp-spec} for authoritative documentation on lock primitives and their semantics.
